{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "- I decided to go with approach 2 \"Share and grab data\". I took 3 other students images which increased my original training images amount by 793 and my original validation images by 224. (total of 1053 training images and 322 validation images)\n",
    "- I chose this approach because by combining my images with other students I created a larger dataset. In theory, this should produce a better model by allowing the model to learn a better approximation (which will increase production performance). \n",
    "- I implemented this approach by:\n",
    "    - downloading the images into their respective digit folders on my google drive to combine.\n",
    "    - retraining the model with a larger dataset in lab 3 \n",
    "    - aquiring 5 examples of each digit in lab 4 and computed accuracy and confusion matrix again for produciton performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model training and Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Lab 3\n",
    "- created a datablock and dataloaders with aug_transforms the same as in lab 3\n",
    "- using a resnet 18 architecture looked at the learning rate/loss graph\n",
    "- ![title](lr.png)\n",
    "- chose a lr of 9e-4 accuracy improved to 0.67 compared to out of the box of 0.37\n",
    "- Performed transfer learning, unfroze and found lr with different landscape (lr = 7e-4)\n",
    "- ![title](lr1.png)\n",
    "- Used discriminative learning rates (9e-5,9e-3)\n",
    "- Played with different batch sizes, 16 and 64, found that the ideal batch size is 16 with 12 epochs\n",
    "- Retrained on the ideal batch size producing the following confusion matrix:\n",
    "- ![title](confmat.png)\n",
    "- saved the best model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lab 3 code done in google colab \n",
    "!pip install -q fastbook\n",
    "\n",
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/content/gdrive/MyDrive/Colab Notebooks/digits')\n",
    "\n",
    "digits = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "                 get_items = get_image_files, \n",
    "                 splitter = set_seed(42),\n",
    "                 get_y = parent_label,\n",
    "                 item_tfms = Resize(640, 'squish'),\n",
    "                 batch_tfms = aug_transforms(size=420, max_rotate = 90, max_zoom = 0.25, pad_mode= 'border'))\n",
    "dls = digits.dataloaders(path, bs = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "lr_min, lr_steep, lr_valley, lr_slide = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(1, base_lr=9e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning\n",
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.fit_one_cycle(2, 9e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze network and find learning rate again with different landscape\n",
    "learn.unfreeze()\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4, lr_max=7e-4)\n",
    "# performance improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrimnative learning rates\n",
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.fit_one_cycle(2, 9e-4)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(12, lr_max=slice(9e-5,9e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size of 16\n",
    "dls = digits.dataloaders(path, bs = 16)\n",
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.fit_one_cycle(2, 9e-4)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(12, lr_max=slice(9e-5,9e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size of 64\n",
    "dls = digits.dataloaders(path, bs = 64)\n",
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.fit_one_cycle(2, 9e-4)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(12, lr_max=slice(9e-5,9e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retraining on ideal bs\n",
    "dls = digits.dataloaders(path, bs = 16)\n",
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.fit_one_cycle(2, 9e-4)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(12, lr_max=slice(9e-5,9e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = Path('/content/gdrive/MyDrive/Colab Notebooks')\n",
    "\n",
    "if not (export_path/'models').exists():\n",
    "  (export_path/'models').mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname=(export_path/\"models/digits_modelNEW.pkl\"))\n",
    "(export_path/\"models\").ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From lab 4\n",
    "- Saved 5 sets of labeled images (using lab4_predict_finger_count_gui.py) for each digit and created a csv with the results\n",
    "- created a matrix with the results and calculated accuracy = 92%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  1  2  3  4  5\n",
      "Actual                  \n",
      "1          5  0  0  0  0\n",
      "2          0  5  0  0  0\n",
      "3          0  1  4  0  0\n",
      "4          0  0  1  4  0\n",
      "5          0  0  0  0  5\n"
     ]
    }
   ],
   "source": [
    "# lab 4 code\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv('lab4-results.csv')\n",
    "\n",
    "actualValue = test_df['actual']\n",
    "predictedValue = test_df['predicted']\n",
    "\n",
    "y_actu = pd.Series(actualValue, name = \"Actual\")\n",
    "y_pred = pd.Series(predictedValue, name = \"Predicted\")\n",
    "df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "print(df_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.0%\n"
     ]
    }
   ],
   "source": [
    "# ACCURACY:\n",
    "correct = 5 + 5 + 4 + 4 + 5\n",
    "total = correct + 1 + 1\n",
    "accuracy = correct/total\n",
    "print(f\"Accuracy: {accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Summary and Conclusion\n",
    "Summary of new results and lab3/lab4 results.\n",
    "Lab 3 results:\n",
    "- Training loss: 0.68\n",
    "- Validation loss: 0.39\n",
    "- Accuracy achieved = 84.8% (validation images)\n",
    "- Three was predicted as four 4 times\n",
    "- Four was predicted as three twice\n",
    "- Two was predicted as three twice\n",
    "\n",
    "Lab 4 results:\n",
    "- Accuracy achieved = 84.0% (production images)\n",
    "- four was predicted as three twice\n",
    "- two was predicted as three once\n",
    "- five was predicted as three once\n",
    "\n",
    "New results:\n",
    "- Training loss: 0.28\n",
    "- Validation loss: 0.15\n",
    "- Accuracy achieved = 95.2% (validation images)\n",
    "- Accuracy achieved = 92.0% (production images)\n",
    "\n",
    "Conclusion: \n",
    "    Due to the approach of using more data to train the model, the perfomance of the classifier improved by 8%. More data should produce a better model; by pulling more (quality) data from others (and augmenting these images) the model gets trained on more variations creating a more complex problem than before. Larger data sets to train on gives the model a chance to learn more features in the contrasting images. This should allow the classifier to reasonably approximate and predict unknown/unseen images. Increased data should often lead to more predictive power for the model.\n",
    "    In this case the model was able to capture the complex data present. This was seen in the training progression where both the losses decreased and the accuracy got better with each epoch. When put into production it was immediatly clear that the model was performing better. Not only did the production accuracy increase but the probability of the correct predictions were all high. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Reflection\n",
    "Include a sentence or two about\n",
    "- I really enjoyed the progression of these labs and how they built off each other. The final product is something to be proud of\n",
    "- Being able to see your model working in real time was like magic. So cool\n",
    "- I was almost hoping my model didnt perform better so I would have to do some digging into why that happened\n",
    "- As always I really enjoyed this course. Thanks for another one Dr.Pauchard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
